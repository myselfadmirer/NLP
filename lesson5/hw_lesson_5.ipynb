{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IkpcHsV8RWHA"
   },
   "source": [
    "## Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAQBOJRARev7"
   },
   "source": [
    "**Написать теггер на данных с руским языком**\n",
    "1. проверить UnigramTagger, BigramTagger, TrigramTagger и их комбмнации\n",
    "2. написать свой теггер как на занятии, попробовать разные векторайзеры, добавить знание не только букв но и слов\n",
    "3. сравнить все реализованные методы сделать выводы\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_16J0ER8WOJx"
   },
   "source": [
    "## загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yPRx8Cu_RDY1",
    "outputId": "9595e8e4-9731-4cfe-a67f-cfb0d9759cd4"
   },
   "outputs": [],
   "source": [
    "# !pip install pyconll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9wgL-33mWUyZ"
   },
   "outputs": [],
   "source": [
    "import pyconll\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "from nltk.tag import DefaultTagger\n",
    "from nltk.tag import UnigramTagger\n",
    "from nltk.tag import BigramTagger, TrigramTagger\n",
    "from nltk.tag import RegexpTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vXxwW9NzW570"
   },
   "outputs": [],
   "source": [
    "# !mkdir datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tpwgA3svWiRw",
    "outputId": "9d4e2aa6-bcc7-4793-f85d-2ce708f88ff8"
   },
   "outputs": [],
   "source": [
    "# !wget -O ./datasets/ru_syntagrus-ud-train.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train.conllu\n",
    "# !wget -O ./datasets/ru_syntagrus-ud-dev.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Oymo30RBWjjl"
   },
   "outputs": [],
   "source": [
    "full_train = pyconll.load_from_file('datasets/ru_syntagrus-ud-train.conllu')\n",
    "full_test = pyconll.load_from_file('datasets/ru_syntagrus-ud-dev.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "\n",
    "for sent in full_train:\n",
    "    set_list = []\n",
    "    for token in sent:\n",
    "        set_list.append((token.form, token.upos))\n",
    "    train_data.append(set_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data\n",
    "# test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "\n",
    "for sent in full_test:\n",
    "    set_list = []\n",
    "    for token in sent:\n",
    "        set_list.append((token.form, token.upos))\n",
    "    test_data.append(set_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XBzFe82cXGNK",
    "outputId": "3c13d3e6-498a-47bc-e729-d2f953cddfb6"
   },
   "outputs": [],
   "source": [
    "test_sent = []\n",
    "\n",
    "for sent in full_test:\n",
    "    for token in sent:\n",
    "        test_sent.append(token.form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = []\n",
    "eval_ = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UnigramTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "OshO48XLXQar"
   },
   "outputs": [],
   "source": [
    "unigram_tagger = UnigramTagger(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8772537323492737"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = unigram_tagger.evaluate(test_data)\n",
    "eval_.append(e)\n",
    "tagger.append('unigram_tagger')\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Алгоритм', None),\n",
       " (',', 'PUNCT'),\n",
       " ('от', 'ADP'),\n",
       " ('имени', 'NOUN'),\n",
       " ('учёного', 'NOUN'),\n",
       " ('аль', 'PART'),\n",
       " ('-', 'PUNCT'),\n",
       " ('Хорезми', None),\n",
       " (',', 'PUNCT'),\n",
       " ('-', 'PUNCT')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(unigram_tagger.tag(test_sent)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## BigramTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6963064064974893"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = bigram_tagger.evaluate(test_data)\n",
    "eval_.append(e)\n",
    "tagger.append('bigram_tagger')\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Алгоритм', None),\n",
       " (',', 'PUNCT'),\n",
       " ('от', 'ADP'),\n",
       " ('имени', 'NOUN'),\n",
       " ('учёного', None),\n",
       " ('аль', None),\n",
       " ('-', 'PUNCT'),\n",
       " ('Хорезми', None),\n",
       " (',', 'PUNCT'),\n",
       " ('-', 'PUNCT')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(bigram_tagger.tag(test_sent)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## BigramTagger в комбинации с UnigramTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_tagger_2 = BigramTagger(train_data, backoff=unigram_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8829828463586425"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = bigram_tagger_2.evaluate(test_data)\n",
    "eval_.append(e)\n",
    "tagger.append('bigram_tagger_2')\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Алгоритм', None),\n",
       " (',', 'PUNCT'),\n",
       " ('от', 'ADP'),\n",
       " ('имени', 'NOUN'),\n",
       " ('учёного', 'NOUN'),\n",
       " ('аль', 'PART'),\n",
       " ('-', 'PUNCT'),\n",
       " ('Хорезми', None),\n",
       " (',', 'PUNCT'),\n",
       " ('-', 'PUNCT')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(bigram_tagger_2.tag(test_sent)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TrigramTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_tagger = TrigramTagger(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24808748694099012"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = trigram_tagger.evaluate(test_data)\n",
    "eval_.append(e)\n",
    "tagger.append('trigram_tagger')\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Алгоритм', None),\n",
       " (',', None),\n",
       " ('от', None),\n",
       " ('имени', None),\n",
       " ('учёного', None),\n",
       " ('аль', None),\n",
       " ('-', 'PUNCT'),\n",
       " ('Хорезми', None),\n",
       " (',', None),\n",
       " ('-', 'PUNCT')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(trigram_tagger.tag(test_sent)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TrigramTagger в комбинации с UnigramTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_tagger_2 = TrigramTagger(train_data, backoff=unigram_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.881769622215482"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = trigram_tagger_2.evaluate(test_data)\n",
    "eval_.append(e)\n",
    "tagger.append('trigram_tagger_2')\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Алгоритм', None),\n",
       " (',', 'PUNCT'),\n",
       " ('от', 'ADP'),\n",
       " ('имени', 'NOUN'),\n",
       " ('учёного', 'NOUN'),\n",
       " ('аль', 'PART'),\n",
       " ('-', 'PUNCT'),\n",
       " ('Хорезми', None),\n",
       " (',', 'PUNCT'),\n",
       " ('-', 'PUNCT')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(trigram_tagger_2.tag(test_sent)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TrigramTagger в комбинации с BigramTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_tagger_3 = TrigramTagger(train_data, backoff=bigram_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6892039901594041"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = trigram_tagger_3.evaluate(test_data)\n",
    "eval_.append(e)\n",
    "tagger.append('trigram_tagger_3')\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Алгоритм', None),\n",
       " (',', 'PUNCT'),\n",
       " ('от', 'ADP'),\n",
       " ('имени', 'NOUN'),\n",
       " ('учёного', None),\n",
       " ('аль', None),\n",
       " ('-', 'PUNCT'),\n",
       " ('Хорезми', None),\n",
       " (',', 'PUNCT'),\n",
       " ('-', 'PUNCT')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(trigram_tagger_3.tag(test_sent)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TrigramTagger в комбинации с BigramTagger в комбинации с UnigramTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_tagger_4 = TrigramTagger(train_data, backoff=bigram_tagger_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.882081353418933"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = trigram_tagger_4.evaluate(test_data)\n",
    "eval_.append(e)\n",
    "tagger.append('trigram_tagger_4')\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Алгоритм', None),\n",
       " (',', 'PUNCT'),\n",
       " ('от', 'ADP'),\n",
       " ('имени', 'NOUN'),\n",
       " ('учёного', 'NOUN'),\n",
       " ('аль', 'PART'),\n",
       " ('-', 'PUNCT'),\n",
       " ('Хорезми', None),\n",
       " (',', 'PUNCT'),\n",
       " ('-', 'PUNCT')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(trigram_tagger_4.tag(test_sent)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Лучший результат у BigramTagger в комбинации с UnigramTagger (0.8829828463586425)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "dj4tV8ytXTry"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tagger</th>\n",
       "      <th>eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unigram_tagger</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bigram_tagger</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trigram_tagger</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trigram_tagger_2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trigram_tagger_3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>trigram_tagger_4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>unigram_tagger</td>\n",
       "      <td>0.877254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bigram_tagger</td>\n",
       "      <td>0.696306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bigram_tagger</td>\n",
       "      <td>0.696306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bigram_tagger_2</td>\n",
       "      <td>0.882983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>trigram_tagger</td>\n",
       "      <td>0.248087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>trigram_tagger_2</td>\n",
       "      <td>0.881770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>trigram_tagger_3</td>\n",
       "      <td>0.689204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>trigram_tagger_4</td>\n",
       "      <td>0.882081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tagger      eval\n",
       "0     unigram_tagger       NaN\n",
       "1      bigram_tagger       NaN\n",
       "2     trigram_tagger       NaN\n",
       "3   trigram_tagger_2       NaN\n",
       "4   trigram_tagger_3       NaN\n",
       "5   trigram_tagger_4       NaN\n",
       "6     unigram_tagger  0.877254\n",
       "7      bigram_tagger  0.696306\n",
       "8      bigram_tagger  0.696306\n",
       "9    bigram_tagger_2  0.882983\n",
       "10    trigram_tagger  0.248087\n",
       "11  trigram_tagger_2  0.881770\n",
       "12  trigram_tagger_3  0.689204\n",
       "13  trigram_tagger_4  0.882081"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'tagger': tagger, 'eval': eval_})\n",
    "result #убрать display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cINqgGpKXURp"
   },
   "source": [
    "# Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCM0drjKXYet"
   },
   "source": [
    "много дополнительных датасетов на русском языке\n",
    "\n",
    "https://natasha.github.io/corus/  \n",
    "https://github.com/natasha/corus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUOg4C8sZNpw"
   },
   "source": [
    "мы будем использовать данные http://www.labinform.ru/pub/named_entities/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzi6ApNLZg6X"
   },
   "source": [
    "**Проверить насколько хорошо работает NER**\n",
    "\n",
    "1. взять нер из nltk\n",
    "2. проверить deeppavlov\n",
    "3. написать свой нер попробовать разные подходы:\n",
    "* передаём в сетку токен и его соседей\n",
    "* передаём в сетку только токен\n",
    "\n",
    "4. сделать выводы по вашим экспериментам какой из подходов успешнее справляется"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aP1LgaNUtaOz"
   },
   "source": [
    "при обучении своего нера не забудьте разделить выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qg6tcss2Zhp9",
    "outputId": "d9b8f633-32e1-4392-be8e-5aefe5ca0444"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: corus in /home/mitko/.local/lib/python3.8/site-packages (0.9.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install corus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "hrc5ocDkaS1e"
   },
   "outputs": [],
   "source": [
    "import corus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vPVv6lhT3ftA",
    "outputId": "ae2f6c07-afc5-4093-b843-eed25d6d749b"
   },
   "outputs": [],
   "source": [
    "# !wget http://www.labinform.ru/pub/named_entities/collection5.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XtLK4z9CH2Ph",
    "outputId": "3abe264a-0f92-48d7-9eb5-76eafdafde8d"
   },
   "outputs": [],
   "source": [
    "# !unzip collection5.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "JPxCa2LyH8gW"
   },
   "outputs": [],
   "source": [
    "bigram_tagger = BigramTagger(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7burz-bD3t4l",
    "outputId": "98119edc-289c-43e7-b67e-17d9ef901c50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Collection5\t   datasets\t     image\t\t  lesson_5.ipynb\n",
      " collection5.zip   HW5_colab.ipynb   lesson5_actual.zip  'ДЗ 5 инструкция.docx'\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UEdS2pAS3fod",
    "outputId": "402714b1-6931-41ce-ef39-f68080d9a29e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ne5Markup(\n",
       "    id='last_28',\n",
       "    text='Распределены кураторы госпрограмм в правительстве РФ\\r\\n\\r\\n\\r\\nБольше других \"работы\" досталось Игорю Шувалову, Ольге Голодец, Аркадию Дворковичу и Дмитрию Рогозину.\\r\\n\\r\\n\\r\\n Премьер Дмитрий Медведев распределил между своими заместителями функции кураторов реализации госпрограмм, сообщается на сайте правительства России.\\r\\n\\r\\nБольше других \"работы\" досталось Игорю Шувалову, Ольге Голодец, Аркадию Дворковичу и Дмитрию Рогозину. Шувалову и Голодец назначено по восемь программ, а Дворкович и Рогозин будут курировать по 11 проектов.\\r\\n\\r\\nКак уточняется на сайте кабмина, в частности вице-премьер по оборонной промышленности Рогозин будет отвечать за противодействие незаконному обороту наркотиков, развитие судостроения и космическую деятельность. Первый вице-премьер Шувалов стал ответственным за инновационную экономику, обеспечение россиян доступным жильем и управление государственными финансами.\\r\\n\\r\\nВице-премьер по соцполитике Ольга Голодец будет курировать, в частности, развитие науки и технологий, пенсионной системы и программу социальной поддержки граждан, а вице-премьер по реальной экономике Дворкович — развитие фармацевтики, лесного хозяйства и энергетики.\\r\\n\\r\\nДмитрий Козак будет отвечать за развитие физкультуры и спорта и региональную политику, глава аппарата правительства Сергей Приходько стал куратором программ по юстиции и развитию сферы массовых коммуникаций и СМИ, а президентский полпред в СКФО Александр Хлопонин будет решать вопросы развития Северного Кавказа.',\n",
       "    spans=[Ne5Span(\n",
       "         index='T1',\n",
       "         type='GEOPOLIT',\n",
       "         start=50,\n",
       "         stop=52,\n",
       "         text='РФ'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T2',\n",
       "         type='PER',\n",
       "         start=91,\n",
       "         stop=105,\n",
       "         text='Игорю Шувалову'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T3',\n",
       "         type='PER',\n",
       "         start=107,\n",
       "         stop=120,\n",
       "         text='Ольге Голодец'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T4',\n",
       "         type='PER',\n",
       "         start=122,\n",
       "         stop=140,\n",
       "         text='Аркадию Дворковичу'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T5',\n",
       "         type='PER',\n",
       "         start=143,\n",
       "         stop=159,\n",
       "         text='Дмитрию Рогозину'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T6',\n",
       "         type='PER',\n",
       "         start=175,\n",
       "         stop=191,\n",
       "         text='Дмитрий Медведев'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T7',\n",
       "         type='GEOPOLIT',\n",
       "         start=307,\n",
       "         stop=313,\n",
       "         text='России'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T8',\n",
       "         type='PER',\n",
       "         start=351,\n",
       "         stop=365,\n",
       "         text='Игорю Шувалову'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T9',\n",
       "         type='PER',\n",
       "         start=367,\n",
       "         stop=380,\n",
       "         text='Ольге Голодец'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T10',\n",
       "         type='PER',\n",
       "         start=382,\n",
       "         stop=400,\n",
       "         text='Аркадию Дворковичу'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T11',\n",
       "         type='PER',\n",
       "         start=403,\n",
       "         stop=419,\n",
       "         text='Дмитрию Рогозину'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T12',\n",
       "         type='PER',\n",
       "         start=421,\n",
       "         stop=429,\n",
       "         text='Шувалову'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T13',\n",
       "         type='PER',\n",
       "         start=432,\n",
       "         stop=439,\n",
       "         text='Голодец'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T14',\n",
       "         type='PER',\n",
       "         start=472,\n",
       "         stop=481,\n",
       "         text='Дворкович'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T15',\n",
       "         type='PER',\n",
       "         start=484,\n",
       "         stop=491,\n",
       "         text='Рогозин'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T16',\n",
       "         type='PER',\n",
       "         start=614,\n",
       "         stop=621,\n",
       "         text='Рогозин'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T17',\n",
       "         type='PER',\n",
       "         start=758,\n",
       "         stop=765,\n",
       "         text='Шувалов'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T18',\n",
       "         type='PER',\n",
       "         start=922,\n",
       "         stop=935,\n",
       "         text='Ольга Голодец'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T19',\n",
       "         type='PER',\n",
       "         start=1094,\n",
       "         stop=1103,\n",
       "         text='Дворкович'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T20',\n",
       "         type='PER',\n",
       "         start=1164,\n",
       "         stop=1177,\n",
       "         text='Дмитрий Козак'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T21',\n",
       "         type='PER',\n",
       "         start=1280,\n",
       "         stop=1296,\n",
       "         text='Сергей Приходько'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T22',\n",
       "         type='MEDIA',\n",
       "         start=1373,\n",
       "         stop=1376,\n",
       "         text='СМИ'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T23',\n",
       "         type='LOC',\n",
       "         start=1404,\n",
       "         stop=1408,\n",
       "         text='СКФО'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T24',\n",
       "         type='PER',\n",
       "         start=1409,\n",
       "         stop=1427,\n",
       "         text='Александр Хлопонин'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T25',\n",
       "         type='LOC',\n",
       "         start=1458,\n",
       "         stop=1475,\n",
       "         text='Северного Кавказа'\n",
       "     )]\n",
       ")"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from corus import load_ne5\n",
    "\n",
    "dir = 'Collection5/'\n",
    "records = load_ne5(dir)\n",
    "next(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrhLNgNwQP2P"
   },
   "source": [
    "процедуры обработки взять из вебинарного ноутбука"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from razdel import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "XDdnL6EXJRt9"
   },
   "outputs": [],
   "source": [
    "words_docs = []\n",
    "for ix, rec in enumerate(records):\n",
    "    words = []\n",
    "    for token in tokenize(rec.text):\n",
    "        type_ent = 'OUT'\n",
    "        for ent in rec.spans:\n",
    "            if (token.start >= ent.start) and (token.stop <= ent.stop):\n",
    "                type_ent = ent.type\n",
    "                break\n",
    "        words.append([token.text, type_ent])\n",
    "    words_docs.extend(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "skYaNCiC5xM4"
   },
   "outputs": [],
   "source": [
    "df_words = pd.DataFrame(words_docs, columns=['word', 'tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OUT         219046\n",
       "PER          21167\n",
       "ORG          13651\n",
       "LOC           4565\n",
       "GEOPOLIT      4354\n",
       "MEDIA         2481\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words['tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Опрос</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>РБК-Украина</td>\n",
       "      <td>MEDIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>:</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word    tag\n",
       "0        Опрос    OUT\n",
       "1  РБК-Украина  MEDIA\n",
       "2            :    OUT"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2kd-emBao1u-",
    "outputId": "a31344d7-177b-4b5f-b49e-4d4201f529ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\n",
      "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.18.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
      "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
      "Requirement already satisfied: inflect in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.0)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
      "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.3.0)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.21.2)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.35)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (54.2.0)\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
      "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.9.0->librosa) (1.14.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.20)\n",
      "Requirement already satisfied: deeppavlov in /usr/local/lib/python3.7/dist-packages (0.14.1)\n",
      "Requirement already satisfied: pandas==0.25.3 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.25.3)\n",
      "Requirement already satisfied: pyopenssl==19.1.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (19.1.0)\n",
      "Requirement already satisfied: ruamel.yaml==0.15.100 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.15.100)\n",
      "Requirement already satisfied: prometheus-client==0.7.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.7.1)\n",
      "Requirement already satisfied: uvicorn==0.11.7 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.11.7)\n",
      "Requirement already satisfied: pydantic==1.3 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (1.3)\n",
      "Requirement already satisfied: fastapi==0.47.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.47.1)\n",
      "Requirement already satisfied: pytelegrambotapi==3.6.7 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (3.6.7)\n",
      "Requirement already satisfied: requests==2.22.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (2.22.0)\n",
      "Requirement already satisfied: Cython==0.29.14 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.29.14)\n",
      "Requirement already satisfied: uvloop==0.14.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.14.0)\n",
      "Requirement already satisfied: numpy==1.18.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (1.18.0)\n",
      "Requirement already satisfied: rusenttokenize==0.0.5 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.0.5)\n",
      "Requirement already satisfied: pytz==2019.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (2019.1)\n",
      "Requirement already satisfied: tqdm==4.41.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (4.41.1)\n",
      "Requirement already satisfied: nltk==3.4.5 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (3.4.5)\n",
      "Requirement already satisfied: aio-pika==6.4.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (6.4.1)\n",
      "Requirement already satisfied: sacremoses==0.0.35 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.0.35)\n",
      "Requirement already satisfied: pymorphy2==0.8 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.8)\n",
      "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (2.10.0)\n",
      "Requirement already satisfied: filelock==3.0.12 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (3.0.12)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (2.4.417127.4579844)\n",
      "Requirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (7.1.2)\n",
      "Requirement already satisfied: overrides==2.7.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn==0.21.2 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.21.2)\n",
      "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (1.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3->deeppavlov) (2.8.1)\n",
      "Requirement already satisfied: cryptography>=2.8 in /usr/local/lib/python3.7/dist-packages (from pyopenssl==19.1.0->deeppavlov) (3.4.7)\n",
      "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from pyopenssl==19.1.0->deeppavlov) (1.15.0)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.11.7->deeppavlov) (0.9.0)\n",
      "Requirement already satisfied: websockets==8.* in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.11.7->deeppavlov) (8.1)\n",
      "Requirement already satisfied: httptools==0.1.*; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"PyPy\" in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.11.7->deeppavlov) (0.1.1)\n",
      "Requirement already satisfied: starlette<=0.12.9,>=0.12.9 in /usr/local/lib/python3.7/dist-packages (from fastapi==0.47.1->deeppavlov) (0.12.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (2020.12.5)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (1.24.3)\n",
      "Requirement already satisfied: yarl in /usr/local/lib/python3.7/dist-packages (from aio-pika==6.4.1->deeppavlov) (1.6.3)\n",
      "Requirement already satisfied: aiormq<4,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from aio-pika==6.4.1->deeppavlov) (3.3.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->deeppavlov) (1.0.1)\n",
      "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2==0.8->deeppavlov) (2.4.393442.3710985)\n",
      "Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.7/dist-packages (from pymorphy2==0.8->deeppavlov) (0.7.2)\n",
      "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (1.14.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from yarl->aio-pika==6.4.1->deeppavlov) (3.7.4.3)\n",
      "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.7/dist-packages (from yarl->aio-pika==6.4.1->deeppavlov) (5.1.0)\n",
      "Requirement already satisfied: pamqp==2.3.0 in /usr/local/lib/python3.7/dist-packages (from aiormq<4,>=3.2.0->aio-pika==6.4.1->deeppavlov) (2.3.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (2.20)\n"
     ]
    }
   ],
   "source": [
    "# установка deeppavlov\n",
    "\n",
    "!pip uninstall -y tensorflow tensorflow-gpu\n",
    "!pip install numpy scipy librosa unidecode inflect librosa transformers\n",
    "!pip install deeppavlov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KY96lqBzsZJ_"
   },
   "outputs": [],
   "source": [
    "#!python -m deeppavlov install squad_bert\n",
    "#!python -m deeppavlov install ner_ontonotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6KE7tpVWs1b7"
   },
   "outputs": [],
   "source": [
    "import deeppavlov\n",
    "from deeppavlov import configs, build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wsegbgCbrzy_",
    "outputId": "98fbfd4e-0fff-433a-9c24-2fa56ab7d241"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-07 09:56:01.170 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/kbqa/datasets/entity_and_type_detection_rus.pickle download because of matching hashes\n",
      "2021-04-07 09:56:20.740 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/kbqa/models/ner_cq_rus.tar.gz download because of matching hashes\n",
      "2021-04-07 09:56:27.228 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/multi_cased_L-12_H-768_A-12.zip download because of matching hashes\n",
      "2021-04-07 09:56:27.635 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_ent_and_type_rus/tag.dict]\n",
      "2021-04-07 09:56:58.169 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/ner_ent_and_type_rus/model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_ent_and_type_rus/model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[['Нью',\n",
       "   '-',\n",
       "   'Йорк',\n",
       "   ',',\n",
       "   'США',\n",
       "   ',',\n",
       "   '30',\n",
       "   'апреля',\n",
       "   '2020',\n",
       "   ',',\n",
       "   '01',\n",
       "   ':',\n",
       "   '01',\n",
       "   '—',\n",
       "   'REGNUM',\n",
       "   'В',\n",
       "   'администрации',\n",
       "   'президента',\n",
       "   'США',\n",
       "   'Дональда',\n",
       "   'Трампа',\n",
       "   'планируют',\n",
       "   'пройти',\n",
       "   'все',\n",
       "   'этапы',\n",
       "   'создания',\n",
       "   'вакцины',\n",
       "   'от',\n",
       "   'коронавируса',\n",
       "   'в',\n",
       "   'ускоренном',\n",
       "   'темпе',\n",
       "   'и',\n",
       "   'выпустить',\n",
       "   '100',\n",
       "   'млн',\n",
       "   'доз',\n",
       "   'до',\n",
       "   'конца',\n",
       "   '2020',\n",
       "   'года',\n",
       "   ',',\n",
       "   'передаёт',\n",
       "   'агентство',\n",
       "   'Bloomberg',\n",
       "   'со',\n",
       "   'ссылкой',\n",
       "   'на',\n",
       "   'осведомлённые',\n",
       "   'источники']],\n",
       " array([[[9.71761167e-01, 2.64181718e-02, 1.82059826e-03],\n",
       "         [9.60046053e-01, 3.84359621e-02, 1.51804090e-03],\n",
       "         [9.21502233e-01, 7.51483515e-02, 3.34933866e-03],\n",
       "         [9.92245018e-01, 6.89126039e-03, 8.63717811e-04],\n",
       "         [9.87261832e-01, 1.17831351e-02, 9.55077179e-04],\n",
       "         [9.96919036e-01, 2.74484046e-03, 3.36058962e-04],\n",
       "         [9.97517467e-01, 2.30196840e-03, 1.80645322e-04],\n",
       "         [9.95577574e-01, 4.12209751e-03, 3.00363230e-04],\n",
       "         [9.91355956e-01, 8.05664156e-03, 5.87437069e-04],\n",
       "         [9.98594940e-01, 1.27561530e-03, 1.29398570e-04],\n",
       "         [9.98789489e-01, 1.13862741e-03, 7.19211675e-05],\n",
       "         [9.97291386e-01, 2.53513828e-03, 1.73508219e-04],\n",
       "         [9.98374701e-01, 1.53756991e-03, 8.77227576e-05],\n",
       "         [9.97647226e-01, 2.15254142e-03, 2.00248949e-04],\n",
       "         [9.96125996e-01, 3.52644222e-03, 3.47553432e-04],\n",
       "         [9.98647392e-01, 1.18941162e-03, 1.63180783e-04],\n",
       "         [9.94467735e-01, 4.99971071e-03, 5.32494334e-04],\n",
       "         [9.88695621e-01, 1.04803387e-02, 8.23963608e-04],\n",
       "         [9.90075767e-01, 8.98968987e-03, 9.34486161e-04],\n",
       "         [1.60550028e-01, 8.38216543e-01, 1.23350031e-03],\n",
       "         [1.39164224e-01, 8.59113455e-01, 1.72229693e-03],\n",
       "         [9.98087585e-01, 1.73141155e-03, 1.80948962e-04],\n",
       "         [9.98838842e-01, 1.03886123e-03, 1.22317724e-04],\n",
       "         [9.98723567e-01, 1.15420937e-03, 1.22209996e-04],\n",
       "         [9.97251451e-01, 2.43649492e-03, 3.12116492e-04],\n",
       "         [9.96265590e-01, 3.32576130e-03, 4.08622727e-04],\n",
       "         [9.88883674e-01, 1.00314673e-02, 1.08485715e-03],\n",
       "         [9.81114209e-01, 1.81934275e-02, 6.92377449e-04],\n",
       "         [3.06576163e-01, 6.90057814e-01, 3.36598023e-03],\n",
       "         [9.96585727e-01, 3.16357287e-03, 2.50688347e-04],\n",
       "         [9.96187031e-01, 3.55201564e-03, 2.60923203e-04],\n",
       "         [9.94267046e-01, 5.20009315e-03, 5.32936596e-04],\n",
       "         [9.98957992e-01, 9.21283732e-04, 1.20748897e-04],\n",
       "         [9.98963594e-01, 9.19635117e-04, 1.16777301e-04],\n",
       "         [9.94871259e-01, 4.77636745e-03, 3.52344301e-04],\n",
       "         [9.92532551e-01, 6.92349765e-03, 5.44037437e-04],\n",
       "         [9.94569838e-01, 4.95819980e-03, 4.71973879e-04],\n",
       "         [9.98663902e-01, 1.20707951e-03, 1.29073000e-04],\n",
       "         [9.97741580e-01, 2.10796879e-03, 1.50471955e-04],\n",
       "         [9.95123923e-01, 4.60237823e-03, 2.73693877e-04],\n",
       "         [9.98261988e-01, 1.58725481e-03, 1.50823776e-04],\n",
       "         [9.98117447e-01, 1.66510267e-03, 2.17488472e-04],\n",
       "         [9.98956561e-01, 9.41986626e-04, 1.01515136e-04],\n",
       "         [9.94731545e-01, 4.65001678e-03, 6.18365128e-04],\n",
       "         [8.65644813e-01, 1.27655372e-01, 6.69975672e-03],\n",
       "         [9.98962879e-01, 9.61940445e-04, 7.51710177e-05],\n",
       "         [9.99106348e-01, 8.36298510e-04, 5.72500976e-05],\n",
       "         [9.98937190e-01, 9.87627311e-04, 7.51964762e-05],\n",
       "         [9.96844649e-01, 2.94215581e-03, 2.13187697e-04],\n",
       "         [9.94291425e-01, 5.16543631e-03, 5.43111411e-04]]], dtype=float32)]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeppavlov_ner = build_model(configs.ner.ner_bert_ent_and_type_rus, download=True)\n",
    "rus_document = \"Нью-Йорк, США, 30 апреля 2020, 01:01 — REGNUM В администрации президента США Дональда Трампа планируют пройти все этапы создания вакцины от коронавируса в ускоренном темпе и выпустить 100 млн доз до конца 2020 года, передаёт агентство Bloomberg со ссылкой на осведомлённые источники\"\n",
    "deeppavlov_ner([rus_document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XQ1phPKisJMz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW5-colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
